\documentclass{article}
\usepackage[dvipsnames]{xcolor}
\usepackage{geometry}[margins=1in]
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[utf8]{inputenc}
\usepackage[square, numbers, sort&compress]{natbib}
\usepackage{minted}
\usepackage{graphicx}
\usepackage{svg}
\usepackage{relsize}

\bibliographystyle{abbrvnat}

\title{\texttt{bigrig}: A historical biogeography range simulator for the
	DEC[+J] and GeoSSE models}
\author{Ben Bettisworth}

\begin{document}

\newcommand{\CountFull}[1]{|#1|_\text{full}}
\newcommand{\CountEmpty}[1]{|#1|_\text{empty}}
\newcommand{\bigrig}{\texttt{bigrig}}
\newcommand{\rand}[2]{#1 \land #2}
\newcommand{\ror}[2]{#1 \lor #2}
\newcommand{\rneg}[1]{\neg #1}
\newcommand{\rxor}[2]{#1 \oplus #2}
\newcommand{\rLshift}[2]{#1 \ll #2}
\newcommand{\rRshift}[2]{#1 \gg #2}

\maketitle

\section{Introduction}

Verifying the correctness of software for computational phylogenetics is an ever
present challenge for tool developers \cite{carver_software_2007,
bettisworth_lagrange-ng_2023}. 
The true phylogenetic tree\textemdash the series of speciation events starting
from a common ancestor which explains an evolutionary history\textemdash is
almost always unobservable, rendering it impossible to verify the results
generated from software tools with a true phylogeny.
Occasionally, researchers will obtain or create known phylogenies
\cite{hillis_experimental_1992} which can be used to verify both models and
software. 
However, datasets for which the truth is known are exceptionally rare, with only
a few such datasets in existence.
Therefore, researchers cannot rely solely on these known phylogenies to
verify the correctness of their tools.

However, without software verification it is difficult to tell the difference
between a surprising result and an error in the software implementation (i.e. a
bug).
Responsible tool developers must therefore turn to artificially generated data
in order to verify the correctness of their programs \cite{ly-trong_alisim_2022,
fletcher_indelible_2009}.
Traditionally artificial data is generated by assuming some statistical model
as the true model, and generating data based on given model parameters.
While this data is unrealistic \cite{trost_simulations_2024}\textemdash failing to
capture the myriad complexities of real biological systems\textemdash it is
still invaluable for the purposes of software verification.

The field of historical biogeography has an analogous problem.
A common goal in historical biogeography is to infer the ancestral ranges
of species along a known phylogenetic tree 
\citep{varela_phylogeny_2019, baker_global_2013, vicente_and_2017}.
However, much like the true phylogenetic tree, these ancestral ranges are
generally not directly observable, and instead must be inferred from the fossil
record \cite{mclachlan_reconstructing_2004}.
But, even if fossils can be used to estimate ancestral ranges, there can be gaps
in the fossil record which make it difficult to be certain about the total
extent of ancestral ranges \cite{kidwell_quality_2002}.
All together, this means that a similar logic applies, and researchers must turn
to simulations in order to verify the correctness of their software which infers
the ancestral ranges.
To date, simulations of biogeographical data using the DEC[+J] model has often
been implemented in an ad hoc matter, with individual tools implementing their
own simulation framework \cite{matzke_statistical_2022,
bettisworth_lagrange-ng_2023}, even though tools which can perform simulations
exist already \citep{hohna_revbayes_2016}.
Sometimes, these simulations utilize the same code for as for the inference of
ancestral ranges and model parameters.
If this is the case, then there is the danger of 
a software error in the inference of the model which will in turn corrupt the
simulation results.

Rather than implementing an ad-hoc simulation for each software project, a
better solution is to write a bespoke implementation of simulation software for
a model (or class of models).
There are several important reasons for this.
First, it is important critical that tools (that is, tools which implement inference for a specific model) are assessed
using a common standard.
By ensuring that a common standard is used to evaluate tools, researchers utilizing tools can be sure that high
performance isn't an artificial result of the evaluation process.

Second, reduces repeated work for tool developers working with the particular
model.
A corollary to this is that a standard simulator lowers the amount of work
required to implement a new tool.
This has the (eventual) result of increasing the number of tools available, and
increasing the overall quality of tooling.

Third, an separation of simulation code and inference code reduces the chances of integrated bugs in both the simulation
and the inference, which might improve apparent performance at the expense of actual performance.
This is to say, if there is an error in a shared region of code between inference and simulation, the error will be
masked, as the simulation step (erroneously) agrees with the inference step.

Fourth and finally, it is significantly easier to perform introspection on the results of a well implemented simulator.
Specifically, events which are typically marginalized over in likelihood models are instead explicit simulated, and
therefore can logged by the simulating program.
For example, a state change along the branch of a phylogenetic tree can be added to a log, which is then reported by the
simulator.
This explicit logging of results ensures the transparency of results, which in turn ensures that the results are
explainable.
This in turn ensures that the bugs \textit{in the simulation} are easier to find, as results which are erroneous will
have erroneous explanations.
Secondly, it ensures that if the inference program is to be extended to estimate these traditionally marginalized
parameters, then the simulator can generate data to test this extension without any modification.

In this paper we present \bigrig{}, a simulator for the \decj{} model which meets the above criteria for a simulator.
For a full explanation of the \decj{} model, please see Section~\ref{sec:model}.
However, here it is important to know that DEC+[J] operates on range data, an absence/presence matrix of data for each
range and taxa in the tree.
Given a set of \decj{} parameters and a phylogenetic tree, \bigrig{} will generate a set of ranges for the taxa at the
tips of the tree.
In addition ranges for inner nodes, cladogenesis events, and state transitions along the branch will be generated.
After generation, \bigrig{} will log the results in one of a variety of formats (YAML, JSON, or CSV), as well as writing
the results in a phylip format, and an annotated tree in newick format.

Furthermore, in this work we show that \bigrig{} is both extremely reliable and extremely performant.
We show that \bigrig{} is reliable with two methods.
The first is by deriving analytical distributions for the results of fundamental operations, and testing to check that
the results are within 0.0001 with 99.999\% reliability.
The second is to perform the simulation with an independent implementation using a slower, but easier to implement
method, and comparing that the results of the two methods agree.
Finally, we show that \bigrig{} is performant by showing that it can generate datasets for trees with tens of thousands
of tips and 63 regions in under 5 \todo{check the time to be sure} seconds using a mid-range laptop.

\section{Background}

Before we describe the methods used to simulate and test the results generated
by \bigrig{}, we will define some terminology and notation.
A range will be written as a binary string, for example \texttt{0101}.
Each position in the string represents a region, with \texttt{1} denoting a full
region, and \texttt{0} denoting an empty region.
As the range is a string, the leading zeros are meaningful.
We denote the total number of regions for a range \( r \) as \( |r| = n\).
We write the number of full regions a region has as \( \CountFull{r} \), and the
number of empty regions as \( \CountEmpty{r} \).
We call a range a ``singleton" if $\CountFull{r} = 1$.
We denote a particular region in a range $r$ as $r_i$, for some index $i$.

Additionally, we define some operations on ranges.
We denote the \textit{bitwise} \textit{and}, \textit{or}, and \textit{exclusive
or} of ranges $r$ and $s$ as $\rand{r}{s}$, $\ror{r}{s}$, $\rxor{r}{s}$
respectively.
We denote the \textit{bitwise} \textit{right shift} and \textit{left shift} of a
range $r$ and a positive integer $n$ as $\rLshift{r}{n}$ and $\rRshift{r}{n}$.
The \textit{bitwise negation} is denoted by $\rneg{r}$.
\textit{Bitwise} indicates that the operation should be performed
region by region. 
For example the \textit{bitwise and} is defined as detail $r_i \land s_i = t_i$
where $0 \leq i \leq |r|$, $\texttt{1} \land \texttt{1} = \texttt{1}$ and is
equal to \texttt{0} otherwise.

These operations are of a particular interest for us as they have either direct
analogues as CPU instructions, or can be trivially computed using a composition
of CPU instructions.
Consequently, computing the results of these operations only requires 1 or 2 CPU
cycles. 
As such, computation of these operations (and functions which are composed of
these operations) is extremely efficient.

\subsection{A Summary of the DEC[+J] Model and its Variants} \label{sec:model}

The Dispersion, Extinction, and Cladogenesis (DEC) model defines the probability
of observing particular geographical history given a pair of parameters for
dispersion and extinction rates.
In this model, there are 3 processes affecting the range of along a phylogenetic
tree.
The first two processes, dispersion and extinction, represent the stochastic
range shifts over time, either newly occupying or vacating a region.
The process is modeled as each region independently transitioning to a
different state (either from full to empty or vise versa) with waiting times
distributed exponentially based on the respective rate.
This is to say, for a region \( r_i \) which is full with extinction
rate \( e \) the waiting time \( w \) for \( r_i \) to transition to empty is \(
w \sim \text{Exp}(e) \) (or $\sim \text{Exp}(d)$ for an empty region.)

The third process is cladogenesis---when a parent species splits into two
daughter species.
The ranges of the daughter species is inherited, possibly with modification,
from the parent's range.
The particular way in which the parent ranges are inherited in the strict DEC
model is governed by a set of 3 scenarios intended to represent realistic
processes of speciation.
In \citet{ALikelihoodFrReeR2005}, these scenarios are simply labeled Scenario 1,
2, and 3, which represent ``copy" (single-range sympatric), allopatric, and
sympatric events, respectively.
In the interest of clarity and memorability, we will use these more common
names, similar to \citet{ModelSelectionMatzke2014}, even though they are not
strictly accurate as only represent a subset of the possible events.

Informally, the three cladogenic scenarios possible in the strict DEC model
are defined as follows: allopatry (or vicariance), where the daughter ranges are
disjoint; sympatry, where the daughter species share some at least one range;
and copy, where both daughter ranges are the same as the parent range.
A copy cladogenic event is distinct from sympatric event as a copy event can
only occur when the parent species occupies only a single region (is a singleton
range).
We give a formal definition of cladogenesis events in
Section~\ref{sec:formal-cladogenesis}.

\citet{ModelSelectionMatzke2014} extended the set of cladogenesis events by
adding a new ``jump" type, intended to represent ``founder-event speciation",
where a small population becomes isolated via colonization of a new area.
Additionally, \citet{ModelSelectionMatzke2014} also allowed for the relative probability
of the cladogenesis events vary.
introducing weights for each of the different cladogenesis types such that a
particular event type can be more likely than the others.

\subsection{A Formal Definition of Cladogenesis Events}
\label{sec:formal-cladogenesis}

A cladogenesis event can be thought of as a tuple of ranges $(p, l, r)$, where
$p$ is the parent range, and $l$ and $r$ are the left and right child ranges,
respectively. For the DEC[+J] model, it is required that at least one of $l$ or
$r$ is a singleton. For the rest of this section, let us suppose that the
singleton range is $l$, without loss of generality.

An assumption by the DEC model is that speciation can only occur in one area,
and therefore at least one of the daughter ranges will be a singleton.
When a cladogenesis event occurs the \textit{strict} DEC model assumes the
probability of these event types is equal.
This is to say, when considering if a particular cladogenesis pattern was the
result of allopatry or sympatry, \textit{strict} DEC considers these events to
have equal weight.
To compute the probability of a particular type of cladogenesis event over the
set \(T = \left\{\text{Allopatry, Sympatry, Copy}\right\}\) we compute
\[
	P(t |
	s) = \frac{C(t | s)}{\sum_{u \in T} C(u | s)},
\]
where \( C(t|s) \) is the
count of cladogenesis events of type $ t $ which are possible given the parent
range \( s \).

Matzke\cite{ModelSelectionMatzke2014} extended the cladogenesis probability
computation by: allowing for a new ``jump" type of cladogenesis events; and
weights for each of the different cladogenesis types such that a particular
type can be more likely than the others.
This pair of modifications to the DEC model are generally denoted as DEC+J,
similar to how gamma rate categories is denoted GTR+G4 in phylogenetic models.
Under this modified model, the probability of a particular type of cladogenesis
event is computed as
\begin{equation}
	P(t | s) = \frac{w_t C(t | s)}{\sum_{u \in T} w_u C(u |
		s)},
\end{equation}
where $w_t$ is the weight for the cladogenesis type $t$.
Additionally, $T$ is augmented by the new type ``jump" to become \(T =
\left\{\text{Allopatry, Sympatry, Copy, Jump}\right\} \).
Informally, ``jump" events are cladogenesis events which allows one of the
daughter species to disperse to a unoccupied range.

We define the cladogenesis event types as
\begin{equation}
T(e) = T(p, l, r) = 
\begin{cases}
  \text{Copy} & \text{if }l = r = p \\ 
  \text{Sympatric} & \text{if } \CountFull{\rand{l}{r}} = 1 \text{ and } \ror{l}{r} = p \\ 
  \text{Allopatric} & \text{if } \CountFull{\rand{l}{r}} = 0 \text{ and } \ror{l}{r} = p   \\ 
  \text{Jump} & \text{if } \CountFull{\rand{l}{r}} = 0 \text{ and } r = p. \\ 
\end{cases}
\label{eq:clad-test}
\end{equation}
Importantly, this definition is in terms of bitwise operations and equality
operations.

For the purposes of simulating a biogeographical history under the \decj{}
model I have broken up the model into two phases: the evolution of a range
\textit{along} a branch, which encompasses both extinction and dispersion; and
the splitting of a range at cladogenesis.
I call these two phases of simulation the spread and the split, respectively.

\subsection{Additional Extensions to the DEC Model}

\section{Methods}

For the purposes of generating data under the DEC[+J] model, there are two
phases to the simulation: range changes \textit{along} a branch(dispersion and
extinction), and range changes at speciation events (cladogenesis).
For the purpose of memnotics, we call these two phases the \textit{spread} and
the \textit{split}.

For both phases, we have implemented two independent methods of simulating
results, with the purpose of checking that the results of the two methods match.
Specifically, we have implemented independent methods with the goal of ensuring
identical results between the two.
The first method of simulating results (for both the spread and split phases) is
rejection sampling.
In rejection sampling, a random result is generated and then checked for
validity.
If the result is valid, it is accepted (possibly with some probability to
correct for the initial distribution).
If the result was invalid, it is rejected and a new result is generated.
In general, rejection methods are very computationally inefficient, as some of
the results generated are simply discarded. 
However, they are extremely reliable and easy to implement.
This is to say, they have a low chance of software errors.

In addition to the rejection method implementations, we additionally implemented 
``fast" methods.
These ``fast" methods implement two major categories of optimizations: analytic
and operational.
Here, an analytic optimization is where we derive a fast algorithm which
analytically ought to generate the correct distribution of results.
On the other hand, an operational optimization is where we implement the
algorithm using efficient operations.
However, just because an algorithm is analytically correct, does not mean it is
\textit{numerically} correct\cite{goldberg_what_1991, noauthor_ieee_1985}.

The other methods of simulating results we have implemented are analytic
methods.
These methods are analytically derived from, and are composed of, operations on
``off the shelf" statistical distributions (E.g. Uniform, Normal, Exponential).
That is, we find an algorithm which ought to generate the correct distribution
of results.
We discuss the details of these optimizations later.

With the independent implementations of both rejection and ``fast" methods, we
can use them to check the results of each other.
That is, by establishing that the results of the two methods are equivalent, in
a rigorous statistical sense, we can establish that if there is a software bug,
it must be present in both methods.
However, the probability of the same software bug being present in both
independent and markedly different implementations is extremely low.
Therefore, if the results of the two methods are statistically equivalent, we
can be extremely confident that the results are correct.

\subsection{Simulating the Spread}

As mentioned in Section~\ref{sec:model}, the evolution of a range along a
branch is modeled as a Poisson process, analogous to the character evolution
models used in phylogenetic inference.

The problem is this: given an initial range \( r \) with \( |r| = n \) regions,
and a branch length \( t \), produce a final range which has undergone
extinction and dispersion at rates \( e \) and \( d \), respectively.
When a range experiences dispersion, it gains a region, and when a range
experiences extinction, it loses a region. 
Each of the regions is treated as an independent process from each other.
This observation is the basis for the rejection method of spread simulation:
randomly generate \( n \) waiting times, labeled \( w_i \), for each region.
Specifically, the waiting times are distributed as
\begin{equation}
	\label{eq:exp-rejection} w_i \sim
	\begin{cases}
		\text{Exp}(e) & \text{if } r_i
		= 1                            \\ \text{Exp}(d) & \text{if } r_i = 0.
	\end{cases}
\end{equation}
Once all $n$ waiting times are generated, we pick the smallest, say $w_i$, and
negate $r_i$.
We repeat this process until the total waiting time exceeds the branch length,
at which point we return a list of transition events, excluding the final event
who's waiting time exceeded the branch length.

Keen readers might already be aware of the fact that if we have a set of
independent processes like above, the entire set can be represented by a single
exponential distribution, with \(w \sim \text{Exp}(t) \) where
\begin{equation}
	\label{eq:exp-param} t = e \times \CountFull{r} + d \times \CountEmpty{r}.
\end{equation}
This second method then is to compute \( t \) using Eq.~\ref{eq:exp-param},
draw a waiting waiting time \( w \sim \text{Exp}(t) \).
Once a time is rolled, we pick a region with weights equal to the exponential
distribution parameter in Eq.~\ref{eq:exp-rejection}.

We implement both of the above methods, but only use the second to preform
simulations.
The first method is used to check the results of the second method.

\subsection{Simulating the Split}

Note that a split can be viewed as an ordered triplet of binary numbers \(
(p,l,r) \), where $p$ is the parent range and $l$ and $r$ are the child ranges.
Therefore, we can simulate a split by generating two random numbers (the parent
split $p$ is given), and rejecting invalid splits.
That is, we accept splits which fall into one of the categories defined in
Section~\ref{sec:model}.
We present a C++ function to determine the split type given three
\mintinline{c++}{uint64_t} (labeled \mintinline{c++}{dist_t}) in
Listing~\ref{lst:determine-split-type}.
Using this function, we reject any split that is of type
\mintinline{c++}{split_type_e::invalid}, and accept otherwise.

In order to implement the weighted split type introduced by Matzke in
\cite{ModelSelectionMatzke2014}, we accept with probability equal to the
normalized split weight.
For example, if the split type weights are $y = 1.0, s = 1.0, v = 1.0, j=1.0$,
then a jump type split will be accepted with probability $j/(y + s + v +
j)$.

To accelerate this process, we implement an optimized version of split
simulation.
First, we generate the split type according to the type weights.
This is done in two cases, singleton and non-singleton.
In the singleton case, we generate a split type from $\{\text{jump},
\text{copy}\}$, weighted accordingly.
In the non-singleton case, we generate a split type from $\{\text{jump},
\text{sympatry}, \text{allopatry}\}$, also weighted accordingly.

The total weight for each type is
\begin{equation}
	w_s = C(s|r) \times u_s
\end{equation}
where $C(s|r)$ is the count of splits of type $s$ that are
possible given region $r$.
For example, for the region \texttt{11} there are 2 ways to split
allopatrically: $(\texttt{10}, \texttt{01})$ and $(\texttt{01},
\texttt{10})$\footnote{Left and right branches are distinguishable, so swaps
	are also valid.}\footnotemark.
Occasionally, it is convenient to refer to the normalized split weight, in
which case we write \( \overline{w_s} \).
The formulas for various counts are
\begin{align*}
  C(\text{allopatry}|r) & =
  \CountFull{r} \times 2 - (2 \text{ if } \CountFull{r} = 2) \\
  C(\text{sympatry}|r)  & = \CountFull{r} \times 2           \\ C(\text{jump}|r) & =
  \CountEmpty{r} \times 2                                    \\ C(\text{copy}|r) & = 2 \\
\end{align*}

\footnotetext{
  This result depends on the process used to count.
	If an region is selected, and then the child to inherit that region is
	selected, you get 4 ways to allopatrically split with 2 full regions.
	That is, a process based counting method gets a different result, where the
	process is a speciation event in a region, and then a random selection of the
	child branch.}

Once a split type is simulated, we generate
a split according to that type by first determining which region will be
flipped\footnotemark.
If the split type is jump, the region is chosen from among the empty regions.
If the split type is allopatry or sympatry, the region is chosen from among the
full regions.
Once the region is flipped, we pick randomly which child gets which region,
with uniform probability.

\footnotetext{If the type is copy, we can simply return the tuple $(p, p, p)$
where $p$ is the parent range.}

\begin{listing}
	\begin{minted}{c++}
split_type_e determine_split_type(dist_t parent_dist, 
                                  dist_t left_dist, 
                                  dist_t right_dist) {
  size_t diff_region_count =
         (left_dist & right_dist).full_region_count();

  if ((left_dist | right_dist) == parent_dist) {
    if (left_dist == right_dist 
        && left_dist.full_region_count() == 1) {
      return split_type_e::singleton;
    }

    if (!left_dist.singleton() 
        && !right_dist.singleton()) {
      return split_type_e::invalid;
    }

    if (diff_region_count == 1) {
      return split_type_e::sympatric;
    }

    if (diff_region_count == 0) {
      return split_type_e::allopatric;
    }
  } else if (left_dist.singleton()
             && diff_region_count == 0
             && right_dist == parent_dist) {
    return split_type_e::jump;
  }
  return split_type_e::invalid;
}
\end{minted}
	\caption{A function to determine the split type given three numbers.}
	\label{lst:determine-split-type}
\end{listing}

\subsubsection{Simulating a Phylogenetic Tree}


\subsection{Testing}

\subsubsection{Spread}

For the purposes of ensuring correct results, we perform 2 types of tests.
The first test pre-computes the expected value of the waiting time given the
model parameters, and performs a t-test against that expected value.
We compute 1,886,084,219 iterations of the spread function, which allows us to
be 99.999\% confident that the error is less than 0.0001.
We perform this test for 7 different regions and 16 different parameter sets.

The second test is a regression test against the rejection method.
We again run both methods for 1,886,084,219 iterations, which again ensures
that the error is less than 0.0001 with 99.999\% confidence.
We perform this test for 5 different initial regions and 16 different parameter
sets.

\subsubsection{Split}

To test that the correct proportion of splits are generated by the simulation,
we simulate a sample of splits, and check that the proportion of generated
splits matches the expected proportion.
Specifically, we check that if there are \(n\) simulations for a given model
and range \( r \), then we should expect that there are \(\overline{w_t} \times
n\) splits of type \( t \).
We model the realized count of split types as being drawn from a normal
distribution, and perform a t-test to ensure that the realized count is
approximately equal to the expected count.
Again, we compute 1,886,084,219 simulations for 10 different ranges and 8
different sets of model parameters, which ensures a 99.999\% confidence that
the error is less than 0.0001.

Like with the spread, we use the slower rejection method to test that the
results of the optimized method are correct.
We run both methods for 487,791,396 iterations and count of generated types for
each.
This number of iterations ensures that the methods produce the same results to
a tolerance of \texttt{1e-4} with 99.999\% confidence.
We perform this test for 5 different parent regions, and 5 different sets of
model parameters.

\section{Results}

\begin{figure}
    \centering
    \includesvg[width=\linewidth, pretex=\relscale{0.5}]{figs/bigrig.times.linreg.svg}
    \caption{Runtime plot}\label{fig:runtime-taxa}
\end{figure}

\begin{figure}
    \centering
    \includesvg[width=\linewidth, pretex=\relscale{0.5}]{figs/bigrig.times.boxplot.svg}
    \caption{Runtime plot}\label{fig:runtime-regions}
\end{figure}

\section{Conclusion}

\section{Acknowledgements}

Many thanks to Alexander I. Jordan for his assistance on deriving and
implementing the statistical tests used to verify the results of \bigrig{}.

\bibliography{references}

\end{document}
