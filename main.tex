\documentclass[a4paper]{article}
\usepackage[dvipsnames]{xcolor}
\usepackage{geometry}[margins=1in]
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[utf8]{inputenc}
\usepackage[square, numbers, sort&compress]{natbib}
\usepackage{minted}
\usepackage{graphicx}
\usepackage{svg}
\usepackage{relsize}
\usepackage{todonotes}

\bibliographystyle{abbrvnat}

\title{\texttt{bigrig}: A historical biogeography range simulator for the
	DEC[+J] and GeoSSE models}
\author{Ben Bettisworth}

\newcommand{\CountFull}[1]{|#1|_\text{full}}
\newcommand{\CountEmpty}[1]{|#1|_\text{empty}}
\newcommand{\bigrig}{\texttt{bigrig}}
\newcommand{\decj}{DEC[+J]}
\newcommand{\rand}[2]{#1 \land #2}
\newcommand{\ror}[2]{#1 \lor #2}
\newcommand{\rneg}[1]{\neg #1}
\newcommand{\rxor}[2]{#1 \oplus #2}
\newcommand{\rLshift}[2]{#1 \ll #2}
\newcommand{\rRshift}[2]{#1 \gg #2}

\begin{document}

\maketitle

\section{Introduction}

Verifying the correctness of software for computational phylogenetics is an ever present challenge for tool developers
\cite{darribaStateSoftwareEvolutionary2018, mendesHowValidateBayesian2025, carver_software_2007,
bettisworth_lagrange-ng_2023}. 
The true phylogenetic tree\textemdash the series of speciation events starting from a common ancestor which explains an
evolutionary history\textemdash is almost always unobservable, rendering it impossible to verify the results generated
from software tools with a true phylogeny.
Occasionally, researchers will obtain or create known phylogenies \cite{hillis_experimental_1992} which can be used to
verify both models and software. 
However, datasets for which the truth is known are exceptionally rare, with only a few such datasets in existence.
Therefore, researchers cannot rely solely on these known phylogenies to verify the correctness of their tools.

Nonetheless, software verification remains vital, as without verification it is difficult to tell the difference between
a surprising result and an erroneous result which is the result of a software error.
Responsible tool developers must therefore turn to artificially generated data in order to verify the correctness of
their programs \cite{mendesHowValidateBayesian2025, ly-trong_alisim_2022, fletcher_indelible_2009}.
Generally, artificial data is generated by assuming some statistical model as accurate, and generating data based on
a given set of model parameters.
Data generated this way is unrealistic as it fails to capture the myriad complexities of real biological systems
\cite{trost_simulations_2024}.
Nonetheless, the use of artificial data is still ubiquitous when verifying software as there exists no real alternative.

The field of historical biogeography has an analogous issue.
A common goal in historical biogeography is to infer the ancestral ranges of species along a known phylogenetic tree
\citep{varela_phylogeny_2019, baker_global_2013, vicente_and_2017}.
However, much like the true phylogenetic tree, these ancestral ranges are generally not directly observable.
They might be inferred from the fossil record \cite{mclachlan_reconstructing_2004}, but there can be multiple
complications which limit knowledge of the true ancestral ranges.
These complications include, but are not limited to: gaps in the fossil record; the study system includes soft bodied
organisms; or a geographical distribution which is unsuited for fossilization \cite{kidwell_quality_2002}.
All together, this indicates that researchers do not have a reliable source of known ancestral ranges and associated
phylogenetic trees, and therefore must turn to simulations in order to verify the correctness of their software tools.
To date, simulations of biogeographical data using the DEC[+J] model has often been implemented in an ad hoc matter,
with individual tools implementing their own simulation framework \cite{matzke_statistical_2022,
bettisworth_lagrange-ng_2023}, even though tools which can perform simulations exist \cite{hohna_revbayes_2016}.
Sometimes, these simulations utilize the same code for as for the inference of ancestral ranges and model parameters.
If this is the case, then there is the danger of a software error in the inference of the model which will in turn
corrupt the simulation results.

Rather than implementing an ad hoc simulation for each software project, a better solution is to write a bespoke
implementation of simulation software for a model (or class of models).
There are several important reasons for this.
First, it is critical that tools which implement inference for a specific model are assessed using a common standard.
In ensuring that a common standard is used to evaluate tools, researchers utilizing tools can be sure that high
performance is not simply a consequence of the evaluation process.

Second, a common simulation tool drastically reduces the amount of duplicated work for tool developers.
A corollary is that a common simulator lowers the amount of work required to implement a new tool, as a high
quality method of generating testing data can be utiliized by developers of novel tools.
This will have the (eventual) result of increasing the number of tools available, and will increase the overall quality
of tooling.

Third, a separation of simulation code and inference code reduces the chances of integrated bugs in both the simulation
and the inference, which might improve apparent performance at the expense of actual performance.
This is to say, if there is an error in a shared region of code between inference and simulation, the error could be
masked, as the simulation step (erroneously) agrees with the inference step.

Fourth and finally, it is significantly easier to perform introspection on the results of a well implemented simulator.
Specifically, events which are typically marginalized over in likelihood models are instead explicitly simulated, and
therefore can recorded for later analysis.
For example, a state change along the branch of a phylogenetic tree can be added to a log.
This explicit logging of results ensures the transparency of results, which in turn ensures that the resulting data are
explainable.
This in turn ensures that the bugs \textit{in the simulation tool} are faster and simpler to find, as results which are
erroneous will have erroneous explanations.
Records of intermediate states and marginalized parameters also enables future tools to implement and test inference of
these parameters without any further modification to the simulation tool.

In this paper we present \bigrig{}, a simulator for the \decj{} \todo{And possibly a limited version of GeoSSE} model
which meets the above criteria for a simulator. For a full explanation of the \decj{} model, please see
Section~\ref{sec:model}.
Given a set of \decj{} parameters and a phylogenetic tree, \bigrig{} will generate a set of ranges for the taxa at the
tips of the tree.
In addition, ranges for inner nodes, cladogenesis events, and state transitions along the branch will be generated.
After generation, \bigrig{} will log the results in one of a variety of formats (YAML, JSON, or CSV), as well as writing
the results in a phylip format, and an annotated tree in newick format.

Furthermore, we show that \bigrig{} is both extremely reliable and extremely performant.
We show that \bigrig{} is reliable using two separate methods.
The first is by deriving expected distributions for the results of fundamental model events, and using statistical
testing ensure the results are within 0.0001 with 99.999\% of type 1 or type 2 error.
The second is to perform the simulation with an independent implementation using a slower, but simpler to implement
method, and performing statistical tests to verify that the results of the two methods agree.
Finally, we show that \bigrig{} is performant by showing that it can generate datasets for trees with tens of thousands
of tips and 63 regions in under 0.5 \todo{check the time to be sure} seconds using a mid-range laptop.

\section{Background}

In the following section, we will describe the methods we use to implement, test, and verify the simulated results
generated by \bigrig{}.
But first in this section, we will introduce some terminology, notation, and the models at hand.
We begin with notation.

In this paper, the possible areas that a taxon can be found is referred to as a \textit{region}.
An area is made up of non-overlapping regions, and all regions together make up the complete area under study.
A \textit{range} describes the absence and presence for every region in an area.
We denote the number of total possible regions (I.E. the size) for a range \( r \) as \( |r| \).
Each region can either be occupied by the species in question, in which case we say it is full, or it can be unoccupied,
in which case we say it is empty.
We write the number of full regions a region has as \( \CountFull{r} \), and the number of empty regions as \(
\CountEmpty{r} \).

Additionally, we define some operations on ranges.
We denote the \textit{bitwise} \textit{and}, \textit{or}, and \textit{exclusive or} of ranges $r$ and $s$ as
$\rand{r}{s}$, $\ror{r}{s}$, $\rxor{r}{s}$ respectively.
We denote the \textit{bitwise} \textit{right shift} and \textit{left shift} of a range $r$ and a positive integer $n$ as
$\rLshift{r}{n}$ and $\rRshift{r}{n}$\footnotemark.
\textit{Bitwise negation} is denoted by $\rneg{r}$.
\textit{Bitwise} indicates that the operation should be independently on each character in the string (that is, each
region). 
For example the \textit{bitwise and} is defined as detail $r_i \land s_i = t_i$ where $0 \leq i \leq |r|$, $\texttt{1}
\land \texttt{1} = \texttt{1}$ and is equal to \texttt{0} otherwise.

\footnotetext{For those that are interested, we do not use a rotating shift in this work.}

These operations are of a particular interest for us as they can be computed using only a few comparatively cheap CPU
instructions.
Consequently, computing the results of these operations often requires less than a single CPU cycle
\cite{Abel19a} \footnotemark.
As such, computation of these operations (and functions which are composed of these operations) is extremely efficient.

\footnotetext{This is due to the capabilities of modern CPUs to dispatch more than one instruction per cycle, depending
on the specific instructions.}

\subsection{A Summary of the DEC model and its Variants} \label{sec:model}

The Dispersion, Extinction, and Cladogenesis (DEC) model defines the probability of observing particular geographical
history given a pair of parameters for dispersion and extinction rates and a phylogenetic tree equipped with branch
lengths. 
In this model, there are 3 processes affecting the range of along a phylogenetic tree.
The first two processes, dispersion and extinction, represent the stochastic range shifts over time, either newly
occupying or vacating a region.
The process is modeled as each region independently transitioning to a different state (either from full to empty or
vise versa) with waiting times distributed exponentially based on the respective rate.
This is to say, for a region \( r_i \) which is full with extinction rate \( e \) the waiting time \( w \) for \( r_i \)
to transition to empty is \( w \sim \text{Exp}(e) \) (or $w \sim \text{Exp}(d)$ to transition an empty region to a full
region).

The third process is cladogenesis, I.E. when a parent species splits into two daughter species.
When this occurs, some regions from the parent's range will be inherited by one daughter, and rest will be inherited by
the other daughter.
The particular way in which the parent ranges are inherited is governed by a set of scenarios.
In the original Ree \textit{et. al.}\cite{ALikelihoodFrReeR2005} paper, these scenarios are simply labeled Scenario 1,
2, and 3.
However, the scenarios are intended to represent realistic cladogenesis methods.
In the interest of clarity and memorability, we will use the more common names, similar to
\citet{ModelSelectionMatzke2014} has done in their paper.

Informally, the three cladogenic scenarios possible in the strict DEC model are defined as follows: allopatry (or
vicariance), where the daughter ranges are disjoint; sympatry, where the daughter species share some at least one range;
and copy, where both daughter ranges are the same as the parent range.
A copy cladogenic event is distinct from sympatric event as a copy event can only occur when the parent species occupies
only a single region (is a singleton range).
We give a formal definition of cladogenesis events in Section~\ref{sec:formal-cladogenesis}.

\citet{ModelSelectionMatzke2014} extended the set of cladogenesis events by adding a new ``jump" type, intended to
represent ``founder-event speciation", where a small population becomes isolated via colonization of a new area.
Additionally, \citet{ModelSelectionMatzke2014} also allowed for the relative probability of the cladogenesis events
vary.
introducing weights for each of the different cladogenesis types such that a particular event type can be more likely
than the others.

\subsection{A Formal Definition of Cladogenesis Events}
\label{sec:formal-cladogenesis}

A cladogenesis event can be thought of as a tuple of ranges $(p, l, r)$, where $p$ is the parent range, and $l$ and $r$
are the left and right child ranges, respectively. 
An assumption by the DEC[+J] model is that speciation occurs instantaneously and is isolated to a single area, and
therefore at least one of the daughter ranges ($l$ or $r$) will be a singleton.
For the rest of this section, let $l$ be the singleton range, without loss of generality.

When a cladogenesis event occurs the \textit{strict} DEC model assumes the probability of any event type is equal.
This is to say, when considering if a particular cladogenesis result was of an allopatric or sympatric, \textit{strict}
DEC considers these events to have equal weight.
To compute the probability of a particular type of cladogenesis event over the set \(T = \left\{\text{Allopatry,
Sympatry, Copy}\right\}\) we compute
\[
	P(t |
	s) = \frac{C(t | p)}{\sum_{u \in T} C(u | p)},
\]
where \( C(t|p) \) is the count of cladogenesis events of type $t$ which are possible given the parent range, and $T$ is
the set of all possible types.

\citet{ModelSelectionMatzke2014} extended the cladogenesis probability computation by adding a new ``jump" type of
cladogenesis event and incorporating weights for each cladogenesis type.
The first addition, the ``jump" type, is intended to model ``founder events''.
The second addition allows for different event types to be relatively more or less likely.
This pair of modifications to the DEC model are generally denoted as DEC+J, similar to how gamma rate categories is
denoted GTR+G4 in phylogenetic models.
Under this modified model, the probability of a particular type of cladogenesis event is computed as
\begin{equation}
	P(t | p) = \frac{w_t C(t | p)}{\sum_{u \in T} w_u C(u | p)},
\end{equation}
where $w_t$ is the weight for the cladogenesis type $t$.
Additionally, $T$ is augmented by the new type ``jump" to become \(T = \left\{\text{Allopatry, Sympatry, Copy,
Jump}\right\} \).
Informally, ``jump" events are cladogenesis events which allows one of the daughter species to disperse to a unoccupied
range.

We define the cladogenesis event types as
\begin{equation}
T(e) = T(p, l, r) = 
\begin{cases}
  \text{Copy} & \text{if }l = r = p \\ 
  \text{Sympatric} & \text{if } \CountFull{\rand{l}{r}} = 1 \text{ and } \ror{l}{r} = p \\ 
  \text{Allopatric} & \text{if } \CountFull{\rand{l}{r}} = 0 \text{ and } \ror{l}{r} = p   \\ 
  \text{Jump} & \text{if } \CountFull{\rand{l}{r}} = 0 \text{ and } r = p. \\ 
\end{cases}
\label{eq:clad-test}
\end{equation}

For the purposes of simulating a biogeographical history under the \decj{} model I have broken up the model into two
phases: the evolution of a range \textit{along} a branch, which encompasses both extinction and dispersion; and the
splitting of a range at cladogenesis.
I call these two phases of simulation the spread and the split, respectively.

% \subsection{Additional Extensions to the \decj Model}

A common practice is to adjust for area connectivity by using a connectivity matrix (alternatively a distance
matrix.)\footnotemark
Here, a user supplies the connectivities as a matrix of scalers intended to represent the ease of movement
between two areas.
Commonly, these matrices are derived from the real distances between the two regions.
These connectivities are then used to adjust the dispersion and jump rates between two areas $i$ and $j$ as
\begin{align*}
  d_{ij} &= d c_{ij}^w \\
  j_{ij} &= j c_{ij}^w,
\end{align*}
where $w$ is an inferred parameter and $c_{ij}$ is the user supplied connectivity between $i$ and $j$.

Some other authors make a distinction between connectivity and distance matrices.
However, whether a connectivity matrix or a distance matrix is used, the operation is the same.
The only difference is the power of the exponent $w$: positive for connectivity matrices, and negative for
distance matrices.
As such, there will not be a distinction made here in this work.

\section{Methods}

For the purposes of generating data under the DEC[+J] model, there are two phases to the simulation: range changes which
occur along a branch (dispersion and extinction), and range changes which occur at speciation events (cladogenesis).
For mnemonic reasons, we will refer to these phases the \textit{spread} and \textit{split} phases.

For both phases, we have implemented two independent methods of data results, with the purpose of checking that the
results of the two methods match. 
Specifically, we have implemented independent methods with the goal of ensuring identical results between the two.
The first method of simulating results (for both the spread and split phases) is rejection sampling.
In rejection sampling, a random result is generated via a process utilize well known distributions and then checked for
validity.
If the result was invalid, it is rejected and a new result is generated, and if the result is valid, it is accepted.
In general, rejection methods are very computationally inefficient, as for sufficiently complicated validity tests, many
results will need to be generated before a result is accepted.
However, they are extremely reliable and easy to implement.
This is to say, they have a low chance of software errors.

In addition to the rejection method implementations, we additionally implemented 
``fast" methods.
These ``fast" methods implement two major categories of optimizations: analytic
and operational.
Here, an analytic optimization is where we derive a fast algorithm which
analytically ought to generate the correct distribution of results.
On the other hand, an operational optimization is where we implement the
algorithm using efficient operations.
However, just because an algorithm is analytically correct, does not mean it is
\textit{numerically} correct\cite{goldberg_what_1991, noauthor_ieee_1985}.

The other methods of simulating results we have implemented are analytic
methods.
These methods are analytically derived from, and are composed of, operations on
``off the shelf" statistical distributions (E.g. Uniform, Normal, Exponential).
That is, we find an algorithm which ought to generate the correct distribution
of results.
We discuss the details of these optimizations later.

With the independent implementations of both rejection and ``fast" methods, we
can use them to check the results of each other.
That is, by establishing that the results of the two methods are equivalent, in
a rigorous statistical sense, we can establish that if there is a software bug,
it must be present in both methods.
However, the probability of the same software bug being present in both
independent and markedly different implementations is extremely low.
Therefore, if the results of the two methods are statistically equivalent, we
can be extremely confident that the results are correct.

\subsection{Simulating the Spread}

As mentioned in Section~\ref{sec:model}, the evolution of a range along a branch is modeled as a Continuous Time Markov
Chain (CTMC), analogous to the character evolution models used in phylogenetic inference.
The CTMC can itself be modeled as a Poisson process, where the waiting time for a state change is drawn from an
exponential distribution.

The problem is this: given an initial range \( r \) with \( |r| = n \) regions, and a branch length \( t \), produce a
final range which has undergone extinction and dispersion at rates \( e \) and \( d \), respectively.
When a range experiences dispersion, it gains a region, and when a range experiences extinction, it loses a region. 
Each of the regions is treated as an independent process from each other.
This observation is the basis for the rejection method of spread simulation: randomly generate \( n \) waiting times,
labeled \( w_i \), for each region.
Specifically, the waiting times are distributed as
\begin{equation}
	\label{eq:exp-rejection} w_i \sim
	\begin{cases}
		\text{Exp}(e) & \text{if } r_i
		= 1                            \\ \text{Exp}(d) & \text{if } r_i = 0.
	\end{cases}
\end{equation}
Once all $n$ waiting times are generated, we pick the smallest, say $w_i$, and
negate $r_i$.
We repeat this process until the total waiting time exceeds the branch length,
at which point we return a list of transition events, excluding the final event
who's waiting time exceeded the branch length.

Keen readers might already be aware of the fact that if we have a set of
independent processes like above, the entire set can be represented by a single
exponential distribution, with \(w \sim \text{Exp}(t) \) where
\begin{equation}
	\label{eq:exp-param} t = e \times \CountFull{r} + d \times \CountEmpty{r}.
\end{equation}
This second method then is to compute \( t \) using Eq.~\ref{eq:exp-param},
draw a waiting waiting time \( w \sim \text{Exp}(t) \).
Once a time is rolled, we pick a region with weights equal to the exponential
distribution parameter in Eq.~\ref{eq:exp-rejection}.

We implement both of the above methods, but only use the second to preform
simulations.
The first method is used to check the results of the second method.

\subsection{Simulating the Split}

Note that a split can be viewed as an ordered triplet of binary numbers \(
(p,l,r) \), where $p$ is the parent range and $l$ and $r$ are the child ranges.
Therefore, we can simulate a split by generating two random numbers (the parent
split $p$ is given), and rejecting invalid splits.
That is, we accept splits which fall into one of the categories defined in
Section~\ref{sec:model}.
We present a C++ function to determine the split type given three
\mintinline{c++}{uint64_t} (labeled \mintinline{c++}{dist_t}) in
Listing~\ref{lst:determine-split-type}.
Using this function, we reject any split that is of type
\mintinline{c++}{split_type_e::invalid}, and accept otherwise.

In order to implement the weighted split type introduced by Matzke in
\cite{ModelSelectionMatzke2014}, we accept with probability equal to the
normalized split weight.
For example, if the split type weights are $y = 1.0, s = 1.0, v = 1.0, j=1.0$,
then a jump type split will be accepted with probability $j/(y + s + v +
j)$.

To accelerate this process, we implement an optimized version of split
simulation.
First, we generate the split type according to the type weights.
This is done in two cases, singleton and non-singleton.
In the singleton case, we generate a split type from $\{\text{jump},
\text{copy}\}$, weighted accordingly.
In the non-singleton case, we generate a split type from $\{\text{jump},
\text{sympatry}, \text{allopatry}\}$, also weighted accordingly.

The total weight for each type is
\begin{equation}
	w_s = C(s|r) \times u_s
\end{equation}
where $C(s|r)$ is the count of splits of type $s$ that are
possible given region $r$.
For example, for the region \texttt{11} there are 2 ways to split
allopatrically: $(\texttt{10}, \texttt{01})$ and $(\texttt{01},
\texttt{10})$\footnote{Left and right branches are distinguishable, so swaps
	are also valid.}\footnotemark.
Occasionally, it is convenient to refer to the normalized split weight, in
which case we write \( \overline{w_s} \).
The formulas for various counts are
\begin{align*}
  C(\text{allopatry}|r) & =
  \CountFull{r} \times 2 - (2 \text{ if } \CountFull{r} = 2) \\
  C(\text{sympatry}|r)  & = \CountFull{r} \times 2           \\ C(\text{jump}|r) & =
  \CountEmpty{r} \times 2                                    \\ C(\text{copy}|r) & = 2 \\
\end{align*}

\footnotetext{
  This result depends on the process used to count.
	If an region is selected, and then the child to inherit that region is
	selected, you get 4 ways to allopatrically split with 2 full regions.
	That is, a process based counting method gets a different result, where the
	process is a speciation event in a region, and then a random selection of the
	child branch.}

Once a split type is simulated, we generate
a split according to that type by first determining which region will be
flipped\footnotemark.
If the split type is jump, the region is chosen from among the empty regions.
If the split type is allopatry or sympatry, the region is chosen from among the
full regions.
Once the region is flipped, we pick randomly which child gets which region,
with uniform probability.

\footnotetext{If the type is copy, we can simply return the tuple $(p, p, p)$
where $p$ is the parent range.}

\begin{listing}
	\begin{minted}{c++}
split_type_e determine_split_type(dist_t parent_dist, 
                                  dist_t left_dist, 
                                  dist_t right_dist) {
  size_t diff_region_count =
         (left_dist & right_dist).full_region_count();

  if ((left_dist | right_dist) == parent_dist) {
    if (left_dist == right_dist 
        && left_dist.full_region_count() == 1) {
      return split_type_e::singleton;
    }

    if (!left_dist.singleton() 
        && !right_dist.singleton()) {
      return split_type_e::invalid;
    }

    if (diff_region_count == 1) {
      return split_type_e::sympatric;
    }

    if (diff_region_count == 0) {
      return split_type_e::allopatric;
    }
  } else if (left_dist.singleton()
             && diff_region_count == 0
             && right_dist == parent_dist) {
    return split_type_e::jump;
  }
  return split_type_e::invalid;
}
\end{minted}
	\caption{A function to determine the split type given three numbers.}
	\label{lst:determine-split-type}
\end{listing}

\subsubsection{Simulating a Phylogenetic Tree}


\subsection{Testing}

\subsubsection{Spread}

For the purposes of ensuring correct results, we perform 2 types of tests.
The first test pre-computes the expected value of the waiting time given the
model parameters, and performs a t-test against that expected value.
We compute 1,886,084,219 iterations of the spread function, which allows us to
be 99.999\% confident that the error is less than 0.0001.
We perform this test for 7 different regions and 16 different parameter sets.

The second test is a regression test against the rejection method.
We again run both methods for 1,886,084,219 iterations, which again ensures
that the error is less than 0.0001 with 99.999\% confidence.
We perform this test for 5 different initial regions and 16 different parameter
sets.

\subsubsection{Split}

To test that the correct proportion of splits are generated by the simulation,
we simulate a sample of splits, and check that the proportion of generated
splits matches the expected proportion.
Specifically, we check that if there are \(n\) simulations for a given model
and range \( r \), then we should expect that there are \(\overline{w_t} \times
n\) splits of type \( t \).
We model the realized count of split types as being drawn from a normal
distribution, and perform a t-test to ensure that the realized count is
approximately equal to the expected count.
Again, we compute 1,886,084,219 simulations for 10 different ranges and 8
different sets of model parameters, which ensures a 99.999\% confidence that
the error is less than 0.0001.

Like with the spread, we use the slower rejection method to test that the
results of the optimized method are correct.
We run both methods for 487,791,396 iterations and count of generated types for
each.
This number of iterations ensures that the methods produce the same results to
a tolerance of \texttt{1e-4} with 99.999\% confidence.
We perform this test for 5 different parent regions, and 5 different sets of
model parameters.

\section{Results}

\begin{figure}
    \centering
    \includesvg[width=\linewidth, pretex=\relscale{0.5}]{figs/bigrig.times.linreg.svg}
    \caption{Runtime plot}\label{fig:runtime-taxa}
\end{figure}

\begin{figure}
    \centering
    \includesvg[width=\linewidth, pretex=\relscale{0.5}]{figs/bigrig.times.boxplot.svg}
    \caption{Runtime plot}\label{fig:runtime-regions}
\end{figure}

\section{Conclusion}

\section{Acknowledgements}

Many thanks to Alexander I. Jordan for his assistance on deriving and
implementing the statistical tests used to verify the results of \bigrig{}.

\bibliography{references}

\end{document}
