%! TeX program = lualatex

\documentclass[a4paper]{article}
\usepackage[dvipsnames]{xcolor}
\usepackage{geometry}[margins=1in]
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[square, numbers, sort&compress]{natbib}
\usepackage{minted}
\usepackage{graphicx}
\usepackage{svg}
\usepackage{relsize}
\usepackage{todonotes}

\bibliographystyle{abbrvnat}

\title{\texttt{bigrig}: A historical biogeography range simulator for the
	DEC[+J] and GeoSSE models}
\author{Ben Bettisworth}

\newcommand{\CountFull}[1]{|#1|_\text{full}}
\newcommand{\CountEmpty}[1]{|#1|_\text{empty}}
\newcommand{\bigrig}{\texttt{bigrig}}
\newcommand{\decj}{DEC[+J]}
\newcommand{\rand}[2]{#1 \land #2}
\newcommand{\ror}[2]{#1 \lor #2}
\newcommand{\rneg}[1]{\neg #1}
\newcommand{\rxor}[2]{#1 \oplus #2}
\newcommand{\rLshift}[2]{#1 \ll #2}
\newcommand{\rRshift}[2]{#1 \gg #2}

\begin{document}

\maketitle

\section{Introduction}

Verifying the correctness of phylogenetics software constitutes a perpetual challenge for tool developers
\cite{darribaStateSoftwareEvolutionary2018, mendesHowValidateBayesian2025, carver_software_2007,
bettisworth_lagrange-ng_2023}. 
The true phylogenetic tree\textemdash the series of speciation events originating from a common ancestor which explain an
evolutionary history\textemdash is almost always unobservable. 
It is, generally,impossible to verify the results generated by software tools with a true, empirical reference phylogeny (but see \cite{hillis_experimental_1992} for one of the few notable exceptions.) 
As it currently stands, datasets for which the truth is known are exceptionally rare.
Therefore, researchers cannot rely solely on these occasional known phylogenies to verify tool correctness.

Nonetheless, software verification remains vital, as without verification it is challenging to discriminate
between a surprising result and an erroneous result which is the result of a software error.
Tool developers must therefore rely on artificial data to verify the correctness of
their programs \cite{mendesHowValidateBayesian2025, ly-trong_alisim_2022, fletcher_indelible_2009}.
Generally, these artificial data are generated by assuming some statistical model of evolution, and subsequently generating these 
data for a given set of model parameters.
Data generated with this approach are unrealistic as they fail to capture the complexities of real biological systems 
\cite{trost_simulations_2024} and the models which are tractable rely upon a myriad of non-realistic assumptions (e.g., that alignment 
sites evolve independently.)
Nonetheless, the use of artificial data is still ubiquitous for software verification as there exists no viable alternative. 
Importantly, software simulators are subject to the same concerns as inference software.
Below, we discuss the methods which we can use to increase our confidence that the implementation of our simulator is correct. 

The field of historical biogeography faces an analogous challenge.
A common goal in historical biogeography is to infer the ancestral ranges of species along a known phylogenetic tree
\citep{varela_phylogeny_2019, baker_global_2013, vicente_and_2017}.
However, similar to the true phylogenetic tree (see above), these ancestral ranges generally can not be directly observed.
Some ancestral ranges can be estimated from the fossil record \cite{mclachlan_reconstructing_2004}, but there can be multiple
complications which can limit our knowledge about the true ancestral ranges.
These complications include, but are not limited to: gaps in the fossil record; the study system includes soft bodied
organisms; or a geographical distribution which is unsuited for fossilization \cite{kidwell_quality_2002}.
Overall, there does not exist a reliable source of known ancestral ranges and associated phylogenetic trees. 
Therefore one must turn to simulations in order to verify the correctness of respective software tools.
To date, biogeographical data simulations under the DEC[+J] model have often been implemented in an ad hoc manner,
with individual tools implementing their own simulation framework \cite{matzke_statistical_2022,
bettisworth_lagrange-ng_2023}, even though tools which can generate simulated data do exist \cite{hohna_revbayes_2016}.
Sometimes, these simulations utilize the same code base for the inference of ancestral ranges and corresponding model parameters.
In such cases it is more likely that a software error in the model inference will also corrupt simulation results.

Instead of implementing ad hoc simulations for each software project, developing an independent stand-alone 
simulation software for a model (or class of models) reduces the aforementioned error margin.
Separating simulation from inference code, as mentioned above, reduces the chances of integrated bugs in both the simulation
and the inference, which might improve apparent performance at the expense of actual performance.
This is to say, if there is an error in a shared region of code between inference and simulation, the error could be
masked, as the simulation step (erroneously) agrees with the inference step.
Furthermore, it is substantially easier to introspect results of a well implemented simulator.
Specifically, events which are typically marginalized over in likelihood models are instead explicitly simulated, and can therefore be recorded for later analysis.
For example, a state change along the branch of a phylogenetic tree can be recorded in a log file.
This explicit logging of results ensures the transparency of results, which in turn guarantees that the resulting data are
explainable.
This also allows to more rapidly identify bugs \textit{in the simulation tool}, as erroneous results will have erroneous explanations.
Additional records of intermediate states and marginalized parameters will also enable future tools to implement and test inference of
these parameters without any further modification to the simulation tool.

Finally, it is critical that tools which implement inferences under a specific model are assessed using a common (simulation) standard.
By using a common standard to evaluate tools one can ensure that improved performance (w.r.t., computational performance or inference accuracy) is not merely a consequence of the evaluation process.
%In addition, a common simulation tool drastically reduces the amount of duplicated work for tool developers.
A common simulator also decreases the amount of work required to implement a new inference tool, as a fast and reliable method of generating testing data can be utilized by developers in the context of iterative development cycles.
This will have the (eventual) result of increasing the number of tools available, and will increase the overall quality of tooling.

In this paper we present \bigrig{}, a simulator for the \decj{} \todo{And possibly a limited version of GeoSSE} model
which complies with all of the aforementioned criteria for simulators.
We explain the the \decj{} model in detail in Section~\ref{sec:model}.
Given a set of \decj{} parameters and a phylogenetic tree, \bigrig{} will generate a range dataset  for the taxa at the
tips of the tree.
In addition, ranges for inner nodes, cladogenesis events, and state transitions along branches will be generated.
After generation, \bigrig{} will log the results in a variety of practical file formats (YAML, JSON, or CSV), as well as output
the results in phylip format, and an annotated tree in Newick format.

Furthermore, we show that \bigrig{} is both highly reliable and extremely computationally efficient in regards to runtime and memory usage.
We show that \bigrig{} is reliable via two distinct approaches.
First, we derive expected distributions for the results of fundamental model events, and perform statistical
tests to ensure that the results are within 0.0001 with 99.999\% of type 1 or type 2 error.
Second, we perform the simulation via a completely independent implementation that uses a slower, yet also simpler-to-implement
method. 
Subsequently, we conduct statistical tests to verify that the results of the two independent implementations agree.
Finally, we show that \bigrig{} is computationally efficient. 
It can generate datasets for trees with tens of thousands of tips and 63 regions in under 0.5 \todo{check the time to be sure} seconds on a mid-range laptop.

\section{Background}

In the context of historical biogeography, an individual geographic sector where a taxon may be present is refered to as a \textit{region}.
An \textit{area} comprises at least two non-overlapping regions, and all regions together represent the entire area under study.
When not otherwise stated, we use the term ``area'' to refer to the area containing \textit{all} regions.
A \textit{range} describes the absence or presence of a specific taxon for every region in an area.
We denote the total number of regions for a range \( r \) as \( |r| \).
Each region can either be occupied, in which case we say it is full, or it can be unoccupied, in which case we say it is
empty.
We write the number of full regions a range has as \( \CountFull{r} \), and the number of empty regions as \(
\CountEmpty{r} \).
We denote the value of the $i$th region of a range as $r_i$.
In practice and for simplicity's sake, we represent ranges as binary strings, with $1$ indicating a full region, and $0$
denoting an empty region.
\todo{Maybe an example?}

For the regions $r$ and $s$ we denote the \textit{bitwise and} operation as $\rand{r}{s}$, the \textit{bitwise or} as $\ror{r}{s}$,
the \textit{bitwise exclusive or} as $\rxor{r}{s}$, and the \textit{bitwise negation} as $\rneg{r}$.
Here, \textit{bitwise} indicates that the operation is executed independently on each character in the string (that is,
each region). 
For example the \textit{bitwise and} is defined as detail $r_i \land s_i = t_i$ where $0 \leq i \leq |r|$, $\texttt{1}
\land \texttt{1} = \texttt{1}$ and is equal to \texttt{0} otherwise.
Additionally, we denote the non-rotating \textit{right shift} as $\rRshift{r}{n}$, and the non-rotating \textit{left shift} as
$\rLshift{r}{n}$, for some positive integer $n$.

These operations are of a particular interest as they can be efficiently computed via fundamental CPU instructions.
Consequently, computing the results of these operations often requires less than a single CPU cycle\footnotemark
\citep{Abel19a}.
As such, computation of these operations (and functions which are composed of these operations) is extremely efficient.

\footnotetext{This is due to the capabilities of modern CPUs to potentially execute more than one instruction per cycle, depending
on the specific instructions to be executed.}

\subsection{A Summary of the DEC model and its Variants} \label{sec:model}

The Dispersion, Extinction, and Cladogenesis (DEC) model defines the probability of observing a given biogeographical
history along a given, fixed phylogenetic tree equiped with branch lengths.
Under this model, there are three processes which govern range evolution.
The first two processes, dispersion and extinction, model the stochastic range shifts over time, by corresponding events that newly
occupy or vacate a region.
The model assumes that each region may independently transition to a different state (either from full to empty or
vise versa) with waiting times which are exponentially distributed according to a free rate parameter.
For instance, a region \( r_i \) which is full with extinction rate \( e \), the waiting time \( w \) for \( r_i \)
to transition to empty is \( w \sim \text{Exp}(e) \).
Alternatively, with a dispersion rate $d$, an empty region may transition to full with waiting time $w \sim \text{Exp}(d)$.

The third process is cladogenesis, that is, when a parent species splits into two daughter species.
During this, some regions from the parental range will be inherited by one daughter, and the remaining ones will be inherited by the
other daughter.
The particular way in which parental ranges are inherited is restricted to a limited set of scenarios.
In the original Ree \textit{et. al.}\cite{ALikelihoodFrReeR2005} paper, these scenarios are simply given as Scenario 1,
2, and 3.
These scenarios are intended to represent realistic cladogenesis events, specifically allopatry, and sympatry, while an
additional scenario was included to describe a single region cladogenesis event.
In the interest of clarity and memorability, we will use the more common names as introduced in \citet{ModelSelectionMatzke2014}.

Informally, the scenarios possible under the strict DEC model are: allopatry (alternatively, vicariance), where the
daughter ranges are disjoint; sympatry, where the daughter species share at least one range; and copy, where both
daughter ranges are identical to the parental range.
A copy event is distinct from a sympatric event as it can only occur when the parental range only comprises a single region
(a singleton).
We provide a formal definition of these cladogenesis events in Section~\ref{sec:formal-cladogenesis}.

\citet{ModelSelectionMatzke2014} extended the set of cladogenesis events by incluidng a novel ``jump" scenario that 
aims to represent ``founder-event speciation".
Here, a small population becomes isolated by colonizing a novel region.
Additionally, \citet{ModelSelectionMatzke2014} also allowed for the relative probability of the cladogenesis events to
vary between datasets.
Under this extension, sympatric events might have a larger weight, and therefore exhibit a higher likelihood, than
allopatric events.
These extensions are generally denoted by DEC+J, similar to how gamma rate categories are denoted by GTR+G4 in
standard phylogenetic models.

The parameters of the strict DEC model are the dispersion and extinction rates ($d$ and $e$), and a fixed phylogenetic tree
with fixed branch lengths. 
\decj{} adds the cladogenesis parameters $s$, $v$, $y$ and $j$, for sympatric, allopatric (vicariance), copy, and jump
events, respectively.

\subsection{A Formal Definition of Cladogenesis Events}
\label{sec:formal-cladogenesis}

We will represent a cladogenesis event as a tuple $(p, l, r)$, where $p$ is the parent range, $l$ is the left child
range, and $r$ is the right child range.
The DEC[+J] model assumes that range inheritance under speciation occurs instantaneously and is confined to a single region \todo{reword this sentence, remove instantaneously}.
Speciation is modeled as taking place in that single region.
Hence, at least one of the daughter ranges ($l$ or $r$) will be a singleton.
For the remainder of this section and without loss of generality, we assume that $l$ is the singleton range.

When a cladogenesis event occurs, the \textit{strict} DEC model assumes equal probability for all event types.
In other words, when considering if a particular cladogenesis event is more likely to be allopatric or sympatric,
the \textit{strict} DEC models these as being equally likely.
To compute the probability of a type of cladogenesis event over the set \(T = \left\{\text{Allopatry, Sympatry,
Copy}\right\}\) we compute
\[
	P(t |
	s) = \frac{C(t | p)}{\sum_{u \in T} C(u | p)},
\]
where \( C(t|p) \) is the count of possible cladogenesis events of type $t$ given the parent range, and $T$ is
the set of \textit{all} possible event types.

The cladogenesis model is extended in \decj{} by including weights and an additional cladogenesis type.
Under this extended model, we compute the probability as 
\begin{equation}
	P(t | p) = \frac{w_t C(t | p)}{\sum_{u \in T} w_u C(u | p)},
\end{equation}
where $w_t$ is the weight of cladogenesis type $t$.
Additionally, $T$ is augmented by the new type ``jump" to become \(T = \left\{\text{Allopatry, Sympatry, Copy,
Jump}\right\} \).
Informally, ``jump" events are cladogenesis events which allow one of the daughter species to disperse to an unoccupied
range.

We define the cladogenesis event type as
\begin{equation}
T(e) = T(p, l, r) := 
\begin{cases}
  \text{Copy} & \text{if }l = r = p \\ 
  \text{Sympatric} & \text{if } \CountFull{\rand{l}{r}} = 1 \text{ and } \ror{l}{r} = p \\ 
  \text{Allopatric} & \text{if } \CountFull{\rand{l}{r}} = 0 \text{ and } \ror{l}{r} = p   \\ 
  \text{Jump} & \text{if } \CountFull{\rand{l}{r}} = 0 \text{ and } r = p. \\ 
\end{cases}
\label{eq:clad-test}
\end{equation}

\subsection{Further \decj Model Extensions}

A common practice in \decj{} analyses is to include information about the ease of dispersions or jumps occurring
between two areas.
This information is typically provided via a connectivity graph, which represents the connectivity between pairs of regions by a
positive number.
These connectivities are often derived by using the geographic distance between a pair of regions.
Then, the dispersion rate and jump weight between a region pair $i$ and $j$ are modified via the provided connectivities
as
\begin{align*}
  d_{ij} &= d c_{ij}^w \\
  j_{ij} &= j c_{ij}^w,
\end{align*}
where $w$ is an inferred parameter and $c_{ij}$ is the user-supplied connectivity between $i$ and $j$.

Some other authors might distinguish between connectivity and distance matrices.
However, regardless of whether a connectivity matrix or a distance matrix is used, the main mathematical operation remains identical.
The only difference is the exponent $w$: it is positive for connectivity matrices, and negative for
distance matrices.
Given that they represent the same underlying concept, we will not further distinguish between distance and connectivity matrices.

\section{Methods}

For generating data under the DEC[+J] model, two simulation phases are required. 
Range changes occurring along a branch (dispersion and extinction) and ranges that occur as a result of speciation events (cladogensis) need to be simulated as separate processes.
For mnemonics, we will refer to these phases as the \textit{spread} and \textit{split} phases.

As already mentioned, for both phases, we implemented two completely independent data simulation methods in order to verify that the
results of these two distinct implementations are numerically identical. 
The first simulation method (for both the spread and split phases) is based on the design pattern of rejection
sampling.
In rejection sampling, samples of a distribution over a complicated sample (say $\Omega$) space are generated by
initially sampling from a distribution over a simpler sample space (say $\Omega'$). 
If a sample drawn from $\Omega'$ is not in $\Omega$, then the sample is rejected as invalid, and we draw a new sample.
This process is repeated until we draw a valid sample\footnotemark.
Rejection sampling can be modified to draw non-uniform distributions by means of rejecting valid samples
by some specified proportion in order to correct for the bias.
The precise rejection probability in this case depends on the specific distributions. 
We will specify the rejection probability in detail when we discuss each method.

\footnotetext{This process can fail to terminate with probability $\lim\limits_{n \to \infty} P(\text{Reject})^n = 0$}

Rejection methods are extremely simple, and therefore easy to implement correctly.
The unfortunate trade-off is that a substantial amount of time is spent on generating ultimately rejected samples. 
The time spent generating invalid samples is ultimately wasted.
Therefore implementing software will necessarily be, to some degree, computationally inefficient.
Rejection sampling is typically only utilized when no other method is capable of producing acceptable results.

In addition to the rejection methods, we implemented ``fast" methods of generating samples for the spread and split phases.
These ``fast" methods implement two major improvements: analytic and CPU-aware optimizations.
Here, an analytic optimization relies on a fast algorithm which will analytically generate samples from the desired distribution.
However, we need to keep in mind that the analytical correctness of an algorithm does not imply that it is \textit{numerically} correct
\cite{goldberg_what_1991, noauthor_ieee_1985}.
In addition, we implement CPU-aware optimizations which leverage the computational capabilities of modern CPUs.

We can then use these independent implementations (rejection and ``fast" method) to verify the simulation results.
By verifying that the results of the two methods are equivalent, in a rigorous statistical sense, we can
deduce that if there is a software bug, it must be present in both methods.
However, the probability of the same software bug being present in two independent and algorithmically distinct different
implementations is extremely low \cite{sklaroff1976, taneja2010}.
Therefore, if the results of the two methods produce statistically equivalent results, we can be confident that the
results are correct.

\todo[inline, color=green!20]{The text has been edited up to here. Beyond this is a rough draft.}

\subsection{Simulating the Spread}

A transition event is the tuple $(p, c, w)$, where $p$ is the parent range, $c$ is the child range, and $w$ is the
waiting time between $p$ and $c$.
As mentioned in Section~\ref{sec:model}, the evolution of a range along a branch follows a Poisson process.
The problem is: given an initial range \( r \) with \( |r| = n \) regions and branch length \( t \), produce a final range which
has undergone the processes of extinction and dispersion at rates of \( e \) and \( d \), respectively.
Each of the regions is treated as an independent process from each other.
This observation is the basis for the rejection method of spread simulation: randomly generate \( n \) waiting times,
labeled \( w_i \), for each region.
Specifically, the waiting times are distributed as
\begin{equation}
	\label{eq:exp-rejection} w_i \sim
	\begin{cases}
		\text{Exp}(e) & \text{if } r_i = 1 \\
    \text{Exp}(d) & \text{if } r_i = 0.
	\end{cases}
\end{equation}
Once all $n$ waiting times have been generated, we find $ i = \text{argmin}(w_i)$ and negate the corresponding
region so that $r_i' := \rneg{r_i}$.
The resulting transition event is then $(r, r', w_i)$.

We repeat the above process until the total waiting time exceeds $t$, the sum of selected $w_i$'s, at which point the
process halts, and we yield the list of transition events, excluding the final generated event.

Keen readers might already be aware of the fact that if we have a set of
independent processes as above, the entire set can be represented via a single
exponential distribution, with \(w \sim \text{Exp}(t) \) where
\begin{equation}
	\label{eq:exp-param} t = e \times \CountFull{r} + d \times \CountEmpty{r}.
\end{equation}
This second method then is to compute \( t \) using Eq.~\ref{eq:exp-param},
draw a waiting waiting time \( w \sim \text{Exp}(t) \).
Once a time is rolled, we pick a region with weights equal to the exponential
distribution parameter in Eq.~\ref{eq:exp-rejection}.\todo{Maybe this should come first?}

We implement both of the above methods, but only use the second to preform
simulations.
The first method is used to check the results of the second method.

\subsection{Simulating the Split}

Note that a split can be viewed as an ordered triplet of binary numbers \(
(p,l,r) \), where $p$ is the parent range and $l$ and $r$ are the respective child ranges.
Therefore, we can simulate a split by generating two random numbers (the parent
split $p$ is given), and rejecting invalid splits.
That is, we accept splits which fall into one of the categories defined in
Section~\ref{sec:model}.
We present a C++ function to determine the split type given three
\mintinline{c++}{uint64_t} (labeled \mintinline{c++}{dist_t}) in
Listing~\ref{lst:determine-split-type}.
Using this function, we reject any split that is of type
\mintinline{c++}{split_type_e::invalid}, and accept otherwise.

In order to implement the weighted split type introduced by Matzke in
\cite{ModelSelectionMatzke2014}, we accept it with a probability that is equal to the
normalized split weight.
For example, if the split type weights are $y = 1.0, s = 1.0, v = 1.0, j=1.0$,
then a jump type split will be accepted with probability $j/(y + s + v +
j)$.

To accelerate this process, we implement an optimized split
simulation procedure.
First, we generate the split type according to the split type weights.
We need to cover two cases, singleton and non-singleton.
In the singleton case, we generate a split type from $\{\text{jump},
\text{copy}\}$, weighted accordingly.
In the non-singleton case, we generate a split type from $\{\text{jump},
\text{sympatry}, \text{allopatry}\}$, also weighted accordingly.

The total weight for each type is
\begin{equation}
	w_s = C(s|r) \times u_s
\end{equation}
where $C(s|r)$ is the count of feasible splits of type $s$ given a region $r$.
For example, for region \texttt{11} there exit two ways to split it
allopatrically: $(\texttt{10}, \texttt{01})$ and $(\texttt{01},
\texttt{10})$\footnote{Left and right branches are distinguishable, so swaps
	are also valid.}\footnotemark.
Occasionally, it is convenient to refer to the normalized split weight, in
which case we write \( \overline{w_s} \).
The formulas for various counts are
\begin{align*}
  C(\text{allopatry}|r) & =
  \CountFull{r} \times 2 - (2 \text{ if } \CountFull{r} = 2) \\
  C(\text{sympatry}|r)  & = \CountFull{r} \times 2           \\ C(\text{jump}|r) & =
  \CountEmpty{r} \times 2                                    \\ C(\text{copy}|r) & = 2 \\
\end{align*}

\footnotetext{
  This result depends on the process used to count.
	If a region is selected, and then the child to inherit that region is
	selected, you get 4 ways to allopatrically split with 2 full regions.
	That is, a process based counting method gets a different result, where the
	process is a speciation event in a region, and then a random selection of the
	child branch.}

Once a split type has been simulated, we generate
a split according to this type by initially determining which region will be
flipped\footnotemark.
If the split type is a jump, the region is chosen from among the empty regions.
If the split type is either allopatry or sympatry, the region is chosen from the
full regions.
Once the region is flipped, we randomly determine which child obtains which region,
with uniform probability.

\footnotetext{If the type is copy, we can simply return the tuple $(p, p, p)$
where $p$ is the parent range.}

\begin{listing}
	\begin{minted}{c++}
split_type_e determine_split_type(dist_t parent_dist, 
                                  dist_t left_dist, 
                                  dist_t right_dist) {
  size_t diff_region_count =
         (left_dist & right_dist).full_region_count();

  if ((left_dist | right_dist) == parent_dist) {
    if (left_dist == right_dist 
        && left_dist.full_region_count() == 1) {
      return split_type_e::singleton;
    }

    if (!left_dist.singleton() 
        && !right_dist.singleton()) {
      return split_type_e::invalid;
    }

    if (diff_region_count == 1) {
      return split_type_e::sympatric;
    }

    if (diff_region_count == 0) {
      return split_type_e::allopatric;
    }
  } else if (left_dist.singleton()
             && diff_region_count == 0
             && right_dist == parent_dist) {
    return split_type_e::jump;
  }
  return split_type_e::invalid;
}
\end{minted}
	\caption{A function to determine the split type given three numbers.}
	\label{lst:determine-split-type}
\end{listing}

\subsubsection{Simulating a Phylogenetic Tree}


\subsection{Testing}

\subsubsection{Spread}

For ensuring correct results and implementations, we conduct two types of tests.
The first test pre-computes the expected value of the waiting time given the
model parameters, and performs a t-test against that expected value.
We compute 1,886,084,219 iterations of the spread function, which allows us to
be 99.999\% confident that the error is less than 0.0001.
We perform this test for 7 different regions and 16 different parameter sets.

The second test is a regression test against the rejection method.
We again run both methods for 1,886,084,219 iterations, which again ensures
that the error is less than 0.0001 with 99.999\% confidence.
We perform this test for 5 different initial regions and 16 different parameter
sets.

\subsubsection{Split}

To assess if the correct proportion of splits are generated by the simulation,
we simulate a sample of splits, and check that the proportion of generated
splits matches the expected proportion.
Specifically, we check this as follows: If there \(n\) simulations are conducted under a given model
and range \( r \), then we expect that  \(\overline{w_t} \times
n\) splits of type \( t \) must have been generated.
We model the realized count of split types by drawing from a normal
distribution, and perform a t-test to ensure that the realized count is
approximately equal to the expected count.
Again, we compute 1,886,084,219 simulations for 10 different ranges and 8
different sets of model parameters, which ensures a 99.999\% confidence that
the error is less than 0.0001.

In analogy to the assessment of spreads, we deploy the slower rejection method to assess the correctness 
of the optimized method.
We run both methods for 487,791,396 iterations and count of generated types for
each.
This number of iterations ensures that the methods produce the same results to
a tolerance of \texttt{1e-4} with 99.999\% confidence.
We perform this test for 5 different parent regions, and 5 different sets of
model parameters.

\section{Results}

\begin{figure}
    \centering
    \includesvg[width=\linewidth, pretex=\relscale{0.5}]{figs/bigrig.times.linreg.svg}
    \caption{Runtime plot}\label{fig:runtime-taxa}
\end{figure}

\begin{figure}
    \centering
    \includesvg[width=\linewidth, pretex=\relscale{0.5}]{figs/bigrig.times.boxplot.svg}
    \caption{Runtime plot}\label{fig:runtime-regions}
\end{figure}

\section{Conclusion}

\section{Acknowledgements}

Many thanks to Alexander I. Jordan from the Computational Statistics group at the Heidelberg Institute for Theoretical Studies for his assistance on deriving and
implementing the statistical tests used to verify the results of \bigrig{}.


\bibliography{references}

\end{document}
